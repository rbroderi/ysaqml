{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ysaqml","text":"<p>ysaqml keeps SQLAlchemy tables in an in-memory SQLite database while their contents are sourced from (and persisted back to) YAML files using the <code>naay</code> parser/dumper. The goal is to keep relational workflows, constraints, and transactional semantics while still reviewing fixtures as plain text in git.</p> <ul> <li>Repository: https://github.com/rbroderi/ysaqml</li> <li>Python package: <code>ysaqml</code></li> <li>Documentation stack: MkDocs + Material with mkdocstrings for the API reference</li> </ul>"},{"location":"#why-ysaqml","title":"Why ysaqml?","text":"<ul> <li>Plain-text fixtures: every table maps to <code>&lt;storage_path&gt;/&lt;table&gt;.yaml</code>, so   reviewers can diff data directly.</li> <li>Deterministic round-trips: naay enforces a strict, string-only YAML   subset, ensuring loads and saves are lossless (including block literals).</li> <li>SQLAlchemy native: use the <code>YamlSqliteEngine</code> context manager or the   <code>ysaqml</code> dialect via <code>create_yaml_engine</code> to wire the synchronizer into any   workflow.</li> <li>Performance aware: tables live in SQLite for fast queries; load/save   operations stream through configurable thread pools to parallelize filesystem   IO.</li> </ul>"},{"location":"#what-lives-here","title":"What lives here?","text":"<p>This documentation mirrors the project README while offering more room for installation guides, usage walkthroughs, and an auto-generated API reference. Use the navigation links to explore each section, or run <code>uv run mkdocs serve</code> locally to view a live preview while editing the docs.</p>"},{"location":"api/","title":"API Reference","text":"<p>The public API is intentionally small so SQLAlchemy users can reason about the synchronizer just like any other engine helper.</p>"},{"location":"api/#primary-entry-points","title":"Primary Entry Points","text":"<ul> <li><code>ysaqml.engine.YamlSqliteEngine</code>: A dataclass-powered context manager that   creates an in-memory SQLite engine, loads YAML files, and flushes rows back to   disk on successful exit. The <code>engine</code> attribute exposes the underlying   SQLAlchemy engine so you can issue queries/manipulations directly.</li> <li><code>ysaqml.engine.create_yaml_engine</code>: Convenience helper that builds an engine   configured for the <code>ysaqml</code> dialect and ensures the YAML sync plugin is   activated.</li> <li>Constants exported from <code>ysaqml</code>: <code>DEFAULT_NAAY_VERSION</code>, <code>NULL_SENTINEL</code>,   <code>BLOB_SENTINEL_BASE85</code>, <code>BLOB_SENTINEL_BASE64</code>, and   <code>BLOB_DEFAULT_SENTINEL</code>.</li> </ul>"},{"location":"api/#mkdocstrings-output","title":"mkdocstrings Output","text":"<p>Context manager that syncs SQLite &lt;-&gt; YAML files via naay.</p> Source code in <code>src/ysaqml/engine.py</code> <pre><code>@dataclass(slots=True)\nclass YamlSqliteEngine:\n    \"\"\"Context manager that syncs SQLite &lt;-&gt; YAML files via naay.\"\"\"\n\n    metadata: MetaData\n    storage_path: Path | str\n    naay_version: str = DEFAULT_NAAY_VERSION\n    null_token: str = NULL_SENTINEL\n    write_workers: int | None = None\n    blob_encoding: str = BLOB_DEFAULT_SENTINEL\n    engine: Engine | None = field(init=False, default=None, repr=False)\n    _sync: YamlSynchronizer = field(init=False, repr=False)\n\n    def __post_init__(self) -&gt; None:\n        \"\"\"Initialize the engine and synchronizer after dataclass initialization.\"\"\"\n        self.storage_path = Path(self.storage_path)\n        self.engine = create_engine(\"sqlite+pysqlite:///:memory:\", future=True)\n        self._sync = YamlSynchronizer(\n            self.metadata,\n            self.storage_path,\n            naay_version=self.naay_version,\n            null_token=self.null_token,\n            write_workers=self.write_workers,\n            blob_encoding=self.blob_encoding,\n        )\n\n    def __enter__(self) -&gt; Self:\n        \"\"\"Enter context manager, creating tables and loading data from YAML files.\"\"\"\n        if self.engine is None:\n            msg = \"YamlSqliteEngine has already been closed\"\n            raise RuntimeError(msg)\n        self.metadata.create_all(self.engine)\n        self.load()\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc: BaseException | None,\n        tb: TracebackType | None,\n    ) -&gt; Literal[False]:\n        \"\"\"Clean up resources and save data if no exception occurred.\"\"\"\n        if exc_type is None:\n            self.save()\n        assert self.engine is not None\n        self.engine.dispose()\n        return False\n\n    # ---------------------------------------------------------------------\n    # Public API\n    def load(self) -&gt; None:\n        \"\"\"Clear SQLite tables and hydrate them from all YAML files.\"\"\"\n        assert self.engine is not None\n        self._sync.load(self.engine)\n\n    def save(self) -&gt; None:\n        \"\"\"Dump every SQLite table into its companion YAML file.\"\"\"\n        assert self.engine is not None\n        self._sync.save(self.engine)\n</code></pre> <p>Create a SQLAlchemy engine configured for the <code>ysaqml</code> dialect.</p> Source code in <code>src/ysaqml/engine.py</code> <pre><code>def create_yaml_engine(\n    metadata: MetaData,\n    storage_path: Path | str,\n    *,\n    naay_version: str = DEFAULT_NAAY_VERSION,\n    null_token: str = NULL_SENTINEL,\n    blob_encoding: str = BLOB_DEFAULT_SENTINEL,\n    plugins: Sequence[Any] | None = None,\n    **engine_kwargs: Any,\n) -&gt; Engine:\n    \"\"\"Create a SQLAlchemy engine configured for the ``ysaqml`` dialect.\"\"\"\n    storage = Path(storage_path)\n    url = URL.create(\"ysaqml\", database=\":memory:\")\n\n    plugin_list = list(plugins or [])\n\n    def _plugin_identifier(value: Any) -&gt; str:\n        if isinstance(value, str):\n            return value\n        name = getattr(value, \"name\", None)\n        if not name:\n            msg = \"plugins must be strings or CreateEnginePlugin classes with a 'name'\"\n            raise TypeError(\n                msg,\n            )\n        return name\n\n    plugin_names = [_plugin_identifier(item) for item in plugin_list]\n    if \"ysaqml.sync\" not in plugin_names:\n        plugin_names.append(YamlSyncPlugin.name)\n\n    engine_kwargs.setdefault(\"future\", True)\n    engine_kwargs.setdefault(\"storage_path\", str(storage))\n    engine_kwargs.setdefault(\"poolclass\", StaticPool)\n\n    connect_args = dict(engine_kwargs.get(\"connect_args\") or {})\n    connect_args.setdefault(\"check_same_thread\", False)\n    engine_kwargs[\"connect_args\"] = connect_args\n    return create_engine(\n        url,\n        metadata=metadata,\n        plugins=plugin_names,\n        naay_version=naay_version,\n        null_token=null_token,\n        blob_encoding=blob_encoding,\n        **engine_kwargs,\n    )\n</code></pre>"},{"location":"api/#ysaqml.engine.YamlSqliteEngine.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter context manager, creating tables and loading data from YAML files.</p> Source code in <code>src/ysaqml/engine.py</code> <pre><code>def __enter__(self) -&gt; Self:\n    \"\"\"Enter context manager, creating tables and loading data from YAML files.\"\"\"\n    if self.engine is None:\n        msg = \"YamlSqliteEngine has already been closed\"\n        raise RuntimeError(msg)\n    self.metadata.create_all(self.engine)\n    self.load()\n    return self\n</code></pre>"},{"location":"api/#ysaqml.engine.YamlSqliteEngine.__exit__","title":"<code>__exit__(exc_type, exc, tb)</code>","text":"<p>Clean up resources and save data if no exception occurred.</p> Source code in <code>src/ysaqml/engine.py</code> <pre><code>def __exit__(\n    self,\n    exc_type: type[BaseException] | None,\n    exc: BaseException | None,\n    tb: TracebackType | None,\n) -&gt; Literal[False]:\n    \"\"\"Clean up resources and save data if no exception occurred.\"\"\"\n    if exc_type is None:\n        self.save()\n    assert self.engine is not None\n    self.engine.dispose()\n    return False\n</code></pre>"},{"location":"api/#ysaqml.engine.YamlSqliteEngine.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Initialize the engine and synchronizer after dataclass initialization.</p> Source code in <code>src/ysaqml/engine.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Initialize the engine and synchronizer after dataclass initialization.\"\"\"\n    self.storage_path = Path(self.storage_path)\n    self.engine = create_engine(\"sqlite+pysqlite:///:memory:\", future=True)\n    self._sync = YamlSynchronizer(\n        self.metadata,\n        self.storage_path,\n        naay_version=self.naay_version,\n        null_token=self.null_token,\n        write_workers=self.write_workers,\n        blob_encoding=self.blob_encoding,\n    )\n</code></pre>"},{"location":"api/#ysaqml.engine.YamlSqliteEngine.load","title":"<code>load()</code>","text":"<p>Clear SQLite tables and hydrate them from all YAML files.</p> Source code in <code>src/ysaqml/engine.py</code> <pre><code>def load(self) -&gt; None:\n    \"\"\"Clear SQLite tables and hydrate them from all YAML files.\"\"\"\n    assert self.engine is not None\n    self._sync.load(self.engine)\n</code></pre>"},{"location":"api/#ysaqml.engine.YamlSqliteEngine.save","title":"<code>save()</code>","text":"<p>Dump every SQLite table into its companion YAML file.</p> Source code in <code>src/ysaqml/engine.py</code> <pre><code>def save(self) -&gt; None:\n    \"\"\"Dump every SQLite table into its companion YAML file.\"\"\"\n    assert self.engine is not None\n    self._sync.save(self.engine)\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#from-pypi","title":"From PyPI","text":"<pre><code>pip install ysaqml\n</code></pre> <p>The published wheel pulls in SQLAlchemy and naay. A Rust compiler is not required because naay ships prebuilt artifacts; wheels fall back to the pure Python implementation automatically when native extensions are unavailable.</p>"},{"location":"installation/#from-source","title":"From Source","text":"<p>Clone the repository and install the package in editable mode. The examples below rely on uv, but any virtual environment manager works.</p> <pre><code>git clone https://github.com/rbroderi/ysaqml.git\ncd ysaqml\nuv pip install -e .[dev]\n</code></pre> <p>Editable installs give you the SQLAlchemy dialect entry points, the test suite, and optional extras such as <code>beartype</code> (enabled via <code>pip install .[beartype]</code>).</p>"},{"location":"installation/#documentation-tooling","title":"Documentation Tooling","text":"<p>The docs are built with MkDocs + Material plus mkdocstrings. Install the required packages and run the built-in commands:</p> <pre><code>uv pip install mkdocs mkdocs-material mkdocstrings[python]\nuv run mkdocs serve\n</code></pre> <p>The live server watches <code>docs/</code> and <code>src/ysaqml/</code> so edits to code or markdown refresh the API reference automatically.</p>"},{"location":"installation/#testing","title":"Testing","text":"<p>All code paths are covered by pytest and mypy. Use uv (or your preferred runner) to execute the checks:</p> <pre><code>uv run pytest\nuv run mypy src tests\nuv run ruff check\n</code></pre> <p>These commands match the CI workflow and keep the documentation examples truthful.</p>"},{"location":"usage/","title":"Usage","text":"<p>This page highlights the most common patterns when working with ysaqml. Every example assumes you already defined SQLAlchemy table metadata (columns, types, constraints) and a directory that stores the YAML fixtures.</p>"},{"location":"usage/#context-managed-engine","title":"Context-Managed Engine","text":"<p>The highest-level entry point is <code>YamlSqliteEngine</code>, which wraps an in-memory SQLite engine plus the YAML synchronizer in a context manager. When entering the context it wipes the SQLite tables, rehydrates them from YAML, and upon a clean exit flushes the rows back to disk.</p> <pre><code>from pathlib import Path\nfrom sqlalchemy import Column, Integer, MetaData, String, Table, select\n\nfrom ysaqml import YamlSqliteEngine\n\nmetadata = MetaData()\nusers = Table(\n    \"users\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"name\", String, nullable=False),\n)\n\nstorage = Path(\"./data\")\n\nwith YamlSqliteEngine(metadata, storage) as backend:\n    engine = backend.engine\n    with engine.begin() as conn:\n        conn.execute(users.insert().values(id=1, name=\"Ada\"))\n        print(conn.execute(select(users)).mappings().all())\n# context exit writes ./data/users.yaml\n</code></pre>"},{"location":"usage/#configuring-blob-encoding-workers","title":"Configuring Blob Encoding &amp; Workers","text":"<p><code>YamlSqliteEngine</code> forwards keyword arguments to the underlying synchronizer. The most common tweaks are:</p> <ul> <li><code>write_workers</code>: controls how many threads parallelize YAML IO. Defaults to   <code>min(32, cpu_count * 4)</code>.</li> <li><code>blob_encoding</code>: choose between the default ASCII85 sentinel or the legacy   Base64 sentinel when serializing <code>LargeBinary</code>/<code>BLOB</code> columns.</li> <li><code>null_token</code> and <code>naay_version</code>: override the sentinel and version header   stored in each YAML document.</li> </ul> <pre><code>with YamlSqliteEngine(\n    metadata,\n    storage,\n    write_workers=8,\n    blob_encoding=ysaqml.BLOB_SENTINEL_BASE64,\n) as backend:\n    ...\n</code></pre>"},{"location":"usage/#dialect-helper","title":"Dialect Helper","text":"<p>If you prefer to manage SQLAlchemy engines yourself, use <code>ysaqml.create_yaml_engine</code>. It wires up the custom <code>ysaqml</code> dialect, registers the sync plugin, and configures SQLite with sensible defaults (in-memory DB, <code>StaticPool</code>, <code>check_same_thread=False</code>).</p> <pre><code>from contextlib import closing\n\nengine = create_yaml_engine(metadata, storage)\nwith closing(engine):\n    with engine.begin() as conn:\n        conn.execute(users.insert().values(id=2, name=\"Grace\"))\n# remember to dispose() or use closing()/contextlib\n</code></pre> <p>Whenever you dispose the engine, the plugin automatically saves every table to its YAML companion. If you keep the engine alive across tests or processes, call <code>engine.dispose()</code> explicitly to flush the data.</p>"},{"location":"usage/#file-layout","title":"File Layout","text":"<p>Each table maps to <code>&lt;storage_path&gt;/&lt;table_name&gt;.yaml</code> with the following schema:</p> <pre><code>_naay_version: \"1.0\"\nrows:\n  - id: \"1\"\n    name: \"Ada\"\n</code></pre> <ul> <li>Values are always strings because naay enforces a strict subset of YAML.</li> <li><code>None</code>/<code>NULL</code> is encoded as <code>ysaqml.NULL_SENTINEL</code> and decoded back when   loading.</li> <li>Binary columns serialize as ASCII85 (or Base64 if configured) using   block-literal formatting so large payloads stay readable in git diffs.</li> </ul>"},{"location":"usage/#concurrency-performance","title":"Concurrency &amp; Performance","text":"<p>Loads and saves stream through a thread pool. Reads gather every table\u2019s YAML payload in parallel before inserting into SQLite, while saves encode SQLite rows and write them out concurrently. Use <code>write_workers=1</code> to disable threading if you need deterministic sequencing, or raise it if IO is the bottleneck.</p> <p>Benchmarks in <code>tests/test_engine.py::test_*_threadpool_benchmark</code> validate that threaded IO is substantially faster than serial runs by simulating slow filesystem access.</p>"}]}